command: predict.py --checkpoint ../checkpoints/finetune/fearless-wildflower-490_rassp1_neims1_224kPretrain_148k/checkpoint-147476
  --output-folder predictions --config-file configs/predict_nist_valid_greedy.yaml
  --data-range 23549:30000
cuda_visible_devices: '2'
dataloader:
  batch_size: 1
  num_workers: 1
dataset:
  data_path: data/nist/valid.jsonl
  data_split: valid
  dataset_name: NIST
general:
  additional_naming_info: greedy
  device: cuda
generation_args:
  do_sample: false
  length_penalty: 1.0
  max_length: 200
  num_beams: 1
  num_return_sequences: 1
  penalty_alpha: null
  temperature: null
  top_k: null
  top_p: null
preprocess_args:
  inference_mode: true
  log_base: 1.28
  log_shift: 29
  max_cumsum: null
  max_mol_repr_len: 100
  max_mz: 500
  max_num_peaks: 300
  mol_repr: smiles
  restrict_intensities: false
  source_token: <nist>
start_loading_time: 31/10/2024 11:46:25
tokenizer_path: tokenizer/tokenizer_mf10M.model
finished_time_utc: 31/10/2024 13:12:15
generation_time: 01:25:45
wall_time_utc: 01:25:49
evaluation_0:
    average_num_of_predictions: '8.595521169748377'
    db_search:
        mean_db_score: '0.3873157933415626'
        mean_fpsd_score_probsort: '0.21946323816488547'
        mean_fpsd_score_similsort: '0.3669967983907125'
        rate_of_spectus_wins_probsort: '0.6956027966071618'
        rate_of_spectus_wins_similsort: '0.8478191432728821'
        rate_of_ties_probsort: '0.09007346417290699'
        rate_of_ties_similsort: '0.09007346417290699'
        ties:
            mean_tie_simils_probsort: '0.8076587411199697'
            mean_tie_simils_similsort: '0.8620786962414255'
            num_of_ties_probsort: '2538'
            num_of_ties_simils_equal_to_1_probsort: '1526'
            num_of_ties_simils_equal_to_1_similsort: '1743'
            num_of_ties_similsort: '2538'
            rate_of_ties_simils_equal_to_1_probsort: '0.6012608353033885'
            rate_of_ties_simils_equal_to_1_similsort: '0.6867612293144209'
    eval_config:
        do_db_search: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        fp_simil_function: tanimoto
        on_the_fly: true
        save_best_predictions: true
        threshold: 0.85
    eval_time: 00:01:02
    formula_stats:
        num_all_correct_formulas: 68348 / 242196
        num_at_least_one_correct_formula: '22724'
        num_correct_formulas_at_best_prob: '16963'
        num_correct_formulas_at_best_simil: '19600'
        rate_of_all_correct_formulas: '0.28220119242266595'
        rate_of_at_least_one_correct_formula: '0.8064733648010789'
        rate_of_correct_formulas_at_best_prob: '0.6020158285126167'
        rate_of_correct_formulas_at_best_simil: '0.6956027966071618'
    hit_at_k_prob: '[(1, 0.3510309827163999), (2, 0.4396848493452106), (3, 0.4852184405720978),
        (4, 0.5114100152606736), (5, 0.5300067430883345), (6, 0.5436703694502608),
        (7, 0.5541399013379706), (8, 0.5601731909003798), (9, 0.5639706143308372),
        (10, 0.5655676615679455)]'
    labels_path: data/nist/valid_with_db_index.jsonl
    molecular_weight_stats:
        mean_mw_difference_best_prob: '6.652469922666275'
        mean_mw_difference_best_simil: '7.17471306101898'
        rate_of_exact_mw_prob: '0.5916172765021116'
        rate_of_exact_mw_simil: '0.6323242360790716'
        rate_of_exact_nominal_mw_prob: '0.6404159420804202'
        rate_of_exact_nominal_mw_simil: '0.6602193278205629'
        rate_of_mw_difference_less_than_1_best_prob: '0.674734712708947'
        rate_of_mw_difference_less_than_1_best_simil: '0.6842460162543919'
    num_datapoints_tested: '28177'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28177, 28041, 27765, 27373, 26789, 25838, 24466,
        22280, 18739, 12729]'
    precise_preds_stats:
        num_precise_preds_probsort: '9444'
        num_precise_preds_similsort: '15791'
        rate_of_precise_preds_probsort: '0.33516698016112434'
        rate_of_precise_preds_similsort: '0.5604216204705966'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 13484), (2, 1215), (6, 51), (3, 776),
            (5, 84), (4, 294), (7, 14), (9, 4), (8, 13), (10, 1)])
        num_1_hits_as_first_probsort: '9891'
        num_1_hits_as_first_similsort: '15936'
        num_fp_simil_fail_prob: '447'
        num_fp_simil_fail_simil: '145'
        rate_of_1_hits_as_first_probsort: '0.3510309827163999'
        rate_of_1_hits_as_first_similsort: '0.5655676615679455'
    start_time_utc: 01/11/2024 13:56:05
    threshold_stats:
        num_better_than_threshold_probsort: '10209'
        num_better_than_threshold_similsort: '16154'
        rate_of_better_than_threshold_probsort: '0.3623167831919651'
        rate_of_better_than_threshold_similsort: '0.5733044681832701'
        threshold: '0.85'
    topk_probsort: '[0.6067790315064481, 0.4961421568650259, 0.455369098389846, 0.43135639346762317,
        0.4130989435822464, 0.4003919982924529, 0.38335067597643135, 0.3679957011186039,
        0.3498658009864752, 0.327634326940079]'
    topk_similsort: '[0.7543125917322752, 0.5612530032447501, 0.4872905237163051,
        0.4364794548393387, 0.39652505956447637, 0.3620418123911654, 0.3298169096622658,
        0.29827787326678634, 0.267716858112628, 0.23556039741139015]'
evaluation_1:
    average_num_of_predictions: '8.595521169748377'
    db_search:
        mean_db_score: '0.3873157933415626'
        mean_fpsd_score_probsort: '0.21946323816488547'
        mean_fpsd_score_similsort: '0.3669967983907125'
        rate_of_spectus_wins_probsort: '0.6956027966071618'
        rate_of_spectus_wins_similsort: '0.8478191432728821'
        rate_of_ties_probsort: '0.09007346417290699'
        rate_of_ties_similsort: '0.09007346417290699'
        ties:
            mean_tie_simils_probsort: '0.8076587411199697'
            mean_tie_simils_similsort: '0.8620786962414255'
            num_of_ties_probsort: '2538'
            num_of_ties_simils_equal_to_1_probsort: '1526'
            num_of_ties_simils_equal_to_1_similsort: '1743'
            num_of_ties_similsort: '2538'
            rate_of_ties_simils_equal_to_1_probsort: '0.6012608353033885'
            rate_of_ties_simils_equal_to_1_similsort: '0.6867612293144209'
    eval_config:
        do_db_search: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        fp_simil_function: tanimoto
        on_the_fly: true
        save_best_predictions: true
        threshold: 0.85
    eval_time: 00:01:15
    formula_stats:
        num_all_correct_formulas: 68348 / 242196
        num_at_least_one_correct_formula: '22724'
        num_correct_formulas_at_best_prob: '16963'
        num_correct_formulas_at_best_simil: '19600'
        rate_of_all_correct_formulas: '0.28220119242266595'
        rate_of_at_least_one_correct_formula: '0.8064733648010789'
        rate_of_correct_formulas_at_best_prob: '0.6020158285126167'
        rate_of_correct_formulas_at_best_simil: '0.6956027966071618'
    hit_at_k_prob: '[(1, 0.3510309827163999), (2, 0.4396848493452106), (3, 0.4852184405720978),
        (4, 0.5114100152606736), (5, 0.5300067430883345), (6, 0.5436703694502608),
        (7, 0.5541399013379706), (8, 0.5601731909003798), (9, 0.5639706143308372),
        (10, 0.5655676615679455)]'
    labels_path: data/nist/valid_with_db_index.jsonl
    molecular_weight_stats:
        mean_absolute_mw_difference_best_prob: '6.652469922666275'
        mean_absolute_mw_difference_best_simil: '7.17471306101898'
        mean_relative_mw_difference_best_prob: 2.40%
        mean_relative_mw_difference_best_simil: 2.60%
        rate_of_exact_mw_prob: '0.5916172765021116'
        rate_of_exact_mw_simil: '0.6323242360790716'
        rate_of_exact_nominal_mw_prob: '0.6404159420804202'
        rate_of_exact_nominal_mw_simil: '0.6602193278205629'
        rate_of_mw_difference_less_than_1_best_prob: '0.674734712708947'
        rate_of_mw_difference_less_than_1_best_simil: '0.6842460162543919'
    num_datapoints_tested: '28177'
    num_empty_preds: '1'
    num_predictions_at_k_counter: '[28177, 28041, 27765, 27373, 26789, 25838, 24466,
        22280, 18739, 12729]'
    precise_preds_stats:
        num_precise_preds_probsort: '9444'
        num_precise_preds_similsort: '15791'
        rate_of_precise_preds_probsort: '0.33516698016112434'
        rate_of_precise_preds_similsort: '0.5604216204705966'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 13484), (2, 1215), (6, 51), (3, 776),
            (5, 84), (4, 294), (7, 14), (9, 4), (8, 13), (10, 1)])
        num_1_hits_as_first_probsort: '9891'
        num_1_hits_as_first_similsort: '15936'
        num_fp_simil_fail_prob: '447'
        num_fp_simil_fail_simil: '145'
        rate_of_1_hits_as_first_probsort: '0.3510309827163999'
        rate_of_1_hits_as_first_similsort: '0.5655676615679455'
    start_time_utc: 05/11/2024 10:26:28
    threshold_stats:
        num_better_than_threshold_probsort: '10209'
        num_better_than_threshold_similsort: '16154'
        rate_of_better_than_threshold_probsort: '0.3623167831919651'
        rate_of_better_than_threshold_similsort: '0.5733044681832701'
        threshold: '0.85'
    topk_probsort: '[0.6067790315064481, 0.4961421568650259, 0.455369098389846, 0.43135639346762317,
        0.4130989435822464, 0.4003919982924529, 0.38335067597643135, 0.3679957011186039,
        0.3498658009864752, 0.327634326940079]'
    topk_similsort: '[0.7543125917322752, 0.5612530032447501, 0.4872905237163051,
        0.4364794548393387, 0.39652505956447637, 0.3620418123911654, 0.3298169096622658,
        0.29827787326678634, 0.267716858112628, 0.23556039741139015]'
